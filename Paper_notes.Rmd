---
title: "Paper_notes"
author: "Viviana Alejandra Rodriguez Romero"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### Watson & Crick, 1953

- Watson, J. D., and F. H. Crick. "Molecular Structure of Nucleic Acids;
a Structure for Deoxyribose Nucleic Acid." Nature 171, no. 4356 (April 25,
1953): 737-38

A new structure of the deoxyribose nucleic acid (D.N.A.). Structures proposed previously are not satisfactory. The new structure has two helical chains rotating about the same axis but in opposite directions. The chains are hydrogen bonded by pairs of single bases from each chain. Also, the pairs should be adenine with thymine, and guanine with cytosine, but it is necessary more experiments to prove this fact.     

### Tumor Analysis Best Practices Working Group, 2004

- Tumor Analysis Best Practices Working Group. "Expression Profiling-Best Practices for Data Generation and Interpretation in Clinical Trials." Nature Reviews. Genetics 5, no. 3 (March 2004): 229-37. doi:10.1038/nrg1297. https://www.ncbi.nlm.nih.gov/pubmed/14970825

Spotted cDNAs, spotted oligonucleotides and Affymetrix arrays are the most used types of microarray platforms. However, the manufacture of them varies from place to place, which decreases the comparability between results from different studies.  Then, standardization processes are required in all points of the microarray analysis for using and interpreting microarray data. Standardization ideas go from laboratory process, using the same control RNA solution, to reporting results, as the MIAME (Minimum Information About A  Microarray  Experiment) proposes.
Experimental design is the first place where the standardization is required. Here is important to consider the number of replications, tissue/cell heterogeneity, and procedural variation. Technical variability, as the quantity and quality of the RNA isolated, as the microarray controls have standardized rules.  Another step that requires standard procedures in the signal generation (normalization). Finally, robust statistical analysis that can handle multicollinearity in small samples to make good predictions are needed.

### Lipshutz  et.al., 1999

Lipshutz, R. J., Fodor, S. P., Gingeras T. R., and Lockhart D. J.. "High Density Synthetic Oligonucleotide Arrays." Nature Genetics 21, no. 1 Suppl (January 1999): 20-24. doi:10.1038/4447. https://www.ncbi.nlm.nih.gov/pubmed/9915496 

The GeneChip probe array is a new method to design high-density, two-dimensional arrays of synthetic oligonucleotides. This array can monitor the expression levels of several genes, since oligonucleotide probes use the same method regardless of the organism under study, with good discrimination between signal and noise.

### Altman & Krzywinski, 2014 

Altman, N., Krzywinski M. “Points of Significance: Sources of Variation.” Nature Methods 12, no. 1 (December 30, 2014): 5–6. doi:10.1038/nmeth.3224

All experiments are exposed to different sources of variability. While some sources affect the internal validity of the experiment, others affect external validity. It is essential to identify the sources of variability, to control or measure them, to have more precise and unbiased estimates. 
Biological variability, for example, phenotype and genotype data, can be controlled by fixing the levels of these variables and randomizing to treatments. 
On another hand, replication increases the precision of the estimates and allows to measure the variability from different sources. Additionally, replications in top layers have more impact on the precision than in later layers. 
Finally, blocking can control both internal and external variability, for example using siblings controls external variability and blocking by a technician controls internal variability. With this reduction in variability, blocking increases power in tests for comparisons between treatments.

### Bolstad et.al., 2003

Bolstad BM, Irizarry RA, Astrand M, Speed TP. “A Comparison of Normalization Methods for High Density Oligonucleotide Array Data Based on Variance and Bias.” Bioinformatics (Oxford, England) 19, no. 2 (January 22, 2003): 185–93.

Normalization aims to remove non-biological variation between arrays. Three different complete-data normalization methods are proposed, all independent of the baseline array and carried at probe level. Cyclic loess uses an MA plot applied to probe intensities of two different arrays ($x_{ki}$ and $x_{kj}$), then a loess regression adjusts the probe intensities. This method can be time-consuming since, under multiple arrays, all the pairwise combinations between probes from different arrays should be done multiple times until no more normalization is required. The contrast-based method uses log-scale transformation to build the MA plots, subsequently, the intensities are adjusted using $n-1$ normalizing curves and finally, data is transformed back using exponentiation. This method is also time-consuming. Quantile normalization aims to make the intensities distributions of many arrays the same by using the mean quantile as the value of the original data.

As a comparison of performance, two baseline array methods are used, scaling and non-linear approaches. Complete-data methods showed more variance reduction as compared with baseline array methods, particularly the quantile method. Also, quantile method showed to be the best method minimizing the differences in pairwise comparisons between arrays, and less bias among the other complete-data methods. 


### Cleveland & William &  Devlin, 1988

Cleveland, William S, Devlin S. “Locally Weighted Regression: An Approach to Regression Analysis by Local Fitting.” Journal of the American Statistical Association 83, no. 403 (1988): 596–610.

Loess stands by locally weighted regression. This is a recurrent process in which a weighted least squares estimation is used at each point using only the q nearest-neighbors. The nearest-neighbors are defined using a distance function, usually the Euclidian distance. Loess also requires a weight function which is the tricube function. The tricube function gives more weight to nearby neighbors, and the weights go down as the distance of the point of interest increases. The loess estimate is a linear combination of the observed values for the dependent variable, and it is an unbiased estimator. However, assumptions of independence, normality and constant variance of the errors should be assesed. 

Loess is more useful than regression when the relationship between independent and dependent variables is not linear. However, loess uses all the dependent variables without allowing a variable selection at the same time than building the model. Also, under a high number of independent variables, smoothing is not recommendable.
